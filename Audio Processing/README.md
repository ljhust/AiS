| Title | Remark |
| :----: | :---- |
|[espnet](https://github.com/espnet/espnet)|End-to-End Speech Processing Toolkit |
|[pytheory](https://github.com/Zelgius/pytheory)|Music Theory for Humans.|
|[kbd-audio](https://github.com/ggerganov/kbd-audio)|Tools for capturing and analysing keyboard input paired with microphone capture üé§‚å®Ô∏è |
|[wav2letter](https://github.com/facebookresearch/wav2letter/)|Facebook AI Research's Automatic Speech Recognition Toolkit |
|[awesome-diarization](https://github.com/wq2012/awesome-diarization)|
|[aubio](https://github.com/aubio/aubio)|a library for audio and music analysis https://aubio.org|
|[essentia](https://github.com/MTG/essentia)|C++ library for audio and music analysis, description and synthesis, including Python bindings |
|[FMA: A Dataset For Music Analysis ](https://github.com/mdeff/fma)|
|[ASRT_SpeechRecognition](https://github.com/nl8590687/ASRT_SpeechRecognition)|A Deep-Learning-Based Chinese Speech Recognition System Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑ‰∏≠ÊñáËØ≠Èü≥ËØÜÂà´Á≥ªÁªü|
|[cli-visualizer](https://github.com/dpayne/cli-visualizer)|CLI based audio visualizer|
|[kaldi](https://github.com/kaldi-asr/kaldi)|This is the official location of the Kaldi project. http://kaldi-asr.org|
|[Speech-Separation-Paper](https://github.com/JusperLee/Speech-Separation-Paper)|A must-read paper for speech separation based on neural networks|
|[Realtime_PyAudio_FFT](https://github.com/tr1pzz/Realtime_PyAudio_FFT)|Realtime audio analysis in Python, using PyAudio and Numpy to extract and visualize FFT features from streaming audio.|
|[AudioMass](https://github.com/pkalogiros/AudioMass)|Free full-featured web-based audio & waveform editing tool|