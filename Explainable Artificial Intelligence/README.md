| Title | Remark |
| :----: | :---- |
| [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)|A Guide for Making Black Box Models Explainable.|
|[interpretable_machine_learning_with_python](https://github.com/jphall663/interpretable_machine_learning_with_python)|Examples of techniques for training interpretable ML models, explaining ML models, and debugging ML models for accuracy, discrimination, and security.|
|[awesome-interpretable-machine-learning](https://github.com/lopusz/awesome-interpretable-machine-learning)||
|[xai_resources](https://github.com/pbiecek/xai_resources)|Interesting resources related to XAI (Explainable Artificial Intelligence)|
|[interpret](https://github.com/interpretml/interpret)|Fit interpretable machine learning models. Explain blackbox machine learning.|
|[captum](https://github.com/pytorch/captum)|Model interpretability and understanding for PyTorch https://captum.ai|
|[lucid](https://github.com/tensorflow/lucid)|A collection of infrastructure and tools for research in neural network interpretability|
|[dtreeviz](https://github.com/parrt/dtreeviz)|A python library for decision tree visualization and model interpretation.|
|[awesome-decision-tree-papers](https://github.com/benedekrozemberczki/awesome-decision-tree-papers)|A collection of research papers on decision, classification and regression trees with implementations.|
|[lit](https://github.com/PAIR-code/lit)|The Language Interpretability Tool: Interactively analyze NLP models for model understanding in an extensible and framework agnostic interface.|
|[shap](https://github.com/slundberg/shap)|A game theoretic approach to explain the output of any machine learning model.|
|[mljar-supervised](https://github.com/mljar/mljar-supervised)|Automates Machine Learning Pipeline with Feature Engineering and Hyper-Parameters Tuning üöÄ|
|[imodels](https://github.com/csinva/imodels)|Interpretable ML package üîç for concise, transparent, and accurate predictive modeling (sklearn-compatible).|
|[DiCE](https://github.com/interpretml/DiCE)|Generate Diverse Counterfactual Explanations for any machine learning model.|
|[gam-changer](https://github.com/interpretml/gam-changer)|Edit machine learning models to reflect human knowledge and values|
