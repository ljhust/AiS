| Title | Remark |
| :----: | :---- |
| [NeuralNetwork-ImageQA](https://github.com/ayushoriginal/NeuralNetwork-ImageQA)|This is a python and keras implementation of the VIS+LSTM visual question answering model.|
|[Attention-on-Attention-for-VQA](https://github.com/SinghJasdeep/Attention-on-Attention-for-VQA)|Visual Question Answering Project with state of the art single Model performance.|
|[vqa-mfb](https://github.com/yuzcccc/vqa-mfb)|
|[TVQA](https://github.com/jayleicn/TVQA)|
|[iQAN](https://github.com/yikang-li/iQAN)|
|[ns-vqa](https://github.com/kexinyi/ns-vqa)|
|[murel.bootstrap.pytorch](https://github.com/Cadene/murel.bootstrap.pytorch)|MUREL (CVPR 2019), a multimodal relational reasoning module for VQA https://arxiv.org/abs/1902.09487|
|[TVQAplus](https://github.com/jayleicn/TVQAplus)|
|[openvqa](https://github.com/MILVLG/openvqa)|A lightweight, scalable, and general framework for visual question answering (VQA) research|
|[awesome-visual-question-answering](https://github.com/jokieleung/awesome-visual-question-answering)|








