| Title | Remark |
| :---: | :----- |
| [Relational Deep Reinforcement Learning](https://arxiv.org/abs/1806.01830) | bring in multi-atten into RL called RRL, **but how exactly in practise** |
|[Key Papers in Deep RL](https://spinningup.openai.com/en/latest/spinningup/keypapers.html)||
|[tensorwatch](https://github.com/microsoft/tensorwatch)|Debugging, monitoring and visualization for Python Machine Learning and Data Science|
|[spinningup](https://github.com/openai/spinningup)|An educational resource to help anyone learn deep reinforcement learning. https://spinningup.openai.com/|
|[deep-neuroevolution](https://github.com/uber-research/deep-neuroevolution)|
|[glow](https://github.com/openai/glow)|Glow: Generative Flow with Invertible 1x1 Convolutions|
|[baselines](https://github.com/openai/baselines)|OpenAI Baselines: high-quality implementations of reinforcement learning algorithms|
|[stable-baselines](https://github.com/hill-a/stable-baselines)|A fork of OpenAI Baselines, implementations of reinforcement learning algorithms |
|[MARL-Papers](https://github.com/LantaoYu/MARL-Papers)|Paper list of multi-agent reinforcement learning (MARL)|
|[deep-reinforcement-learning-papers](https://github.com/junhyukoh/deep-reinforcement-learning-papers)|
|[pytorch-a2c-ppo-acktr-gail](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail)|PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO), Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR) and Generative Adversarial Imitation Learning (GAIL).|
|[Deep-Reinforcement-Learning-Algorithms-with-PyTorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch)|




