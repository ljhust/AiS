{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljhust/AiS/blob/master/kaggle/autox_tutorial_santander.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7BwI--biasv",
        "outputId": "54277659-fb2c-4ffd-9231-ebf81330f701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'AutoX' already exists and is not an empty directory.\n",
            "Requirement already satisfied: pytorch_tabnet in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (1.0.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (1.19.5)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (1.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (4.62.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch_tabnet) (3.10.0.2)\n",
            "Processing ./AutoX\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (2.2.3)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (0.90)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (1.1.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (4.62.3)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (from autox==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm->autox==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm->autox==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna->autox==0.1.0) (0.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna->autox==0.1.0) (3.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->autox==0.1.0) (21.3)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna->autox==0.1.0) (1.7.5)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna->autox==0.1.0) (3.9.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna->autox==0.1.0) (6.6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->autox==0.1.0) (1.4.27)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna->autox==0.1.0) (3.0.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->autox==0.1.0) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->autox==0.1.0) (4.8.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->autox==0.1.0) (1.1.6)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->autox==0.1.0) (5.4.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->autox==0.1.0) (5.8.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->autox==0.1.0) (2.3.2)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->autox==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->autox==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->autox==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->autox==0.1.0) (21.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->autox==0.1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->autox==0.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->autox==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna->autox==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->autox==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autox==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->autox==0.1.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->autox==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm->autox==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm->autox==0.1.0) (1.1.0)\n",
            "Building wheels for collected packages: autox\n",
            "  Building wheel for autox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autox: filename=autox-0.1.0-py3-none-any.whl size=58439 sha256=cd2be1cba066767aa4a0c9fa7296cdd6253e00d4a1fe46d7029ca3637033b631\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3juzhlv6/wheels/c1/92/79/4621a04a2f8d505409990c52376798b5b8f555d30af436f510\n",
            "Successfully built autox\n",
            "Installing collected packages: autox\n",
            "  Attempting uninstall: autox\n",
            "    Found existing installation: autox 0.1.0\n",
            "    Uninstalling autox-0.1.0:\n",
            "      Successfully uninstalled autox-0.1.0\n",
            "Successfully installed autox-0.1.0\n"
          ]
        }
      ],
      "source": [
        "# 安装autox\n",
        "# !git clone https://github.com/4paradigm/AutoX.git\n",
        "# !pip install pytorch_tabnet\n",
        "# !pip install ./AutoX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLxEXTfjjAm6",
        "outputId": "aba62a3b-6bf3-48aa-853b-5cd264d8db0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 91% 113M/125M [00:01<00:00, 50.2MB/s]\n",
            "100% 125M/125M [00:02<00:00, 61.7MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/462k [00:00<?, ?B/s]\n",
            "100% 462k/462k [00:00<00:00, 139MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 93% 116M/125M [00:03<00:00, 30.2MB/s] \n",
            "100% 125M/125M [00:03<00:00, 41.3MB/s]\n",
            "AutoX\t     sample_data\t\tSantander     train.csv.zip\n",
            "kaggle.json  sample_submission.csv.zip\ttest.csv.zip\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "\n",
            "3 archives were successfully processed.\n",
            "mkdir: cannot create directory ‘Santander’: File exists\n"
          ]
        }
      ],
      "source": [
        "# 下载 Santander Customer Transaction Prediction数据集\n",
        "\n",
        "# Info on how to get your api key (kaggle.json) here: https://github.com/Kaggle/kaggle-api#api-credentials\n",
        "!pip install kaggle\n",
        "\n",
        "# replace api_token with yours\n",
        "api_token = {\"username\":\"xxx\",\"key\":\"xxx\"}\n",
        "\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "!mkdir ~/.kaggle\n",
        "with open('./kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ./kaggle.json\n",
        "!cp ./kaggle.json ~/.kaggle/\n",
        "!kaggle competitions download -c santander-customer-transaction-prediction\n",
        "\n",
        "!ls\n",
        "!unzip \"*.zip\"\n",
        "!rm -rf *.zip\n",
        "\n",
        "!mkdir Santander\n",
        "!mv ./*.csv Santander"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JVStd4Ql7tC",
        "outputId": "3ff4656d-e0e9-4339-dfa3-52e7b9a48d9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "   INFO ->  [+] read train.csv\n",
            "   INFO ->  Memory usage of dataframe is 308.23 MB\n",
            "   INFO ->  Memory usage after optimization is: 83.77 MB\n",
            "   INFO ->  Decreased by 72.8%\n",
            "   INFO ->  table = train.csv, shape = (200000, 202)\n",
            "   INFO ->  [+] read test.csv\n",
            "   INFO ->  Memory usage of dataframe is 306.70 MB\n",
            "   INFO ->  Memory usage after optimization is: 83.58 MB\n",
            "   INFO ->  Decreased by 72.7%\n",
            "   INFO ->  table = test.csv, shape = (200000, 201)\n",
            "   INFO ->  [+] read sample_submission.csv\n",
            "   INFO ->  Memory usage of dataframe is 3.05 MB\n",
            "   INFO ->  Memory usage after optimization is: 7.48 MB\n",
            "   INFO ->  Decreased by -145.1%\n",
            "   INFO ->  table = sample_submission.csv, shape = (200000, 2)\n"
          ]
        }
      ],
      "source": [
        "from autox import AutoX\n",
        "\n",
        "path = f'./Santander'\n",
        "autox = AutoX(target = 'target', train_name = 'train.csv', test_name = 'test.csv', \n",
        "               id = ['ID_code'], path = path\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlLT7I83mhyp",
        "outputId": "e4f7df03-3254-4ddb-bdbb-9de2a945603f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "   INFO ->  start feature engineer\n",
            "   INFO ->  feature engineer: one2M\n",
            "   INFO ->  featureOne2M ops: {}\n",
            "   INFO ->  ignore featureOne2M\n",
            "   INFO ->  feature engineer: time\n",
            "   INFO ->  featureTime ops: []\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  feature engineer: Cumsum\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  featureCumsum ops: {}\n",
            "   INFO ->  feature engineer: Shift\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  featureShift ops: {}\n",
            "   INFO ->  feature engineer: Diff\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  featureDiff ops: {}\n",
            "   INFO ->  feature engineer: Stat\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  featureStat ops: {}\n",
            "   INFO ->  feature engineer: NLP\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  featureNlp ops: []\n",
            "   INFO ->  feature engineer: Count\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  featureCount ops: []\n",
            "   INFO ->  feature engineer: Rank\n",
            "0it [00:00, ?it/s]\n",
            "   INFO ->  featureRank ops: {}\n",
            "100%|██████████| 202/202 [00:00<00:00, 356.31it/s]\n",
            "   INFO ->  label_encoder_list: ['ID_code']\n",
            "   INFO ->  ordinal_encoder_list: []\n",
            "   INFO ->  feature combination\n",
            "100%|██████████| 8/8 [00:00<00:00, 440.58it/s]\n",
            "   INFO ->  shape of FE_all: (400000, 203), shape of train: (200000, 203), shape of test: (200000, 203)\n",
            "   INFO ->  feature filter\n",
            "100%|██████████| 202/202 [00:05<00:00, 35.04it/s]\n",
            "   INFO ->  filtered features: ['ID_code', 'target', 'ID_code_encoder']\n",
            "   INFO ->  used_features: ['var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7', 'var_8', 'var_9', 'var_10', 'var_11', 'var_12', 'var_13', 'var_14', 'var_15', 'var_16', 'var_17', 'var_18', 'var_19', 'var_20', 'var_21', 'var_22', 'var_23', 'var_24', 'var_25', 'var_26', 'var_27', 'var_28', 'var_29', 'var_30', 'var_31', 'var_32', 'var_33', 'var_34', 'var_35', 'var_36', 'var_37', 'var_38', 'var_39', 'var_40', 'var_41', 'var_42', 'var_43', 'var_44', 'var_45', 'var_46', 'var_47', 'var_48', 'var_49', 'var_50', 'var_51', 'var_52', 'var_53', 'var_54', 'var_55', 'var_56', 'var_57', 'var_58', 'var_59', 'var_60', 'var_61', 'var_62', 'var_63', 'var_64', 'var_65', 'var_66', 'var_67', 'var_68', 'var_69', 'var_70', 'var_71', 'var_72', 'var_73', 'var_74', 'var_75', 'var_76', 'var_77', 'var_78', 'var_79', 'var_80', 'var_81', 'var_82', 'var_83', 'var_84', 'var_85', 'var_86', 'var_87', 'var_88', 'var_89', 'var_90', 'var_91', 'var_92', 'var_93', 'var_94', 'var_95', 'var_96', 'var_97', 'var_98', 'var_99', 'var_100', 'var_101', 'var_102', 'var_103', 'var_104', 'var_105', 'var_106', 'var_107', 'var_108', 'var_109', 'var_110', 'var_111', 'var_112', 'var_113', 'var_114', 'var_115', 'var_116', 'var_117', 'var_118', 'var_119', 'var_120', 'var_121', 'var_122', 'var_123', 'var_124', 'var_125', 'var_126', 'var_127', 'var_128', 'var_129', 'var_130', 'var_131', 'var_132', 'var_133', 'var_134', 'var_135', 'var_136', 'var_137', 'var_138', 'var_139', 'var_140', 'var_141', 'var_142', 'var_143', 'var_144', 'var_145', 'var_146', 'var_147', 'var_148', 'var_149', 'var_150', 'var_151', 'var_152', 'var_153', 'var_154', 'var_155', 'var_156', 'var_157', 'var_158', 'var_159', 'var_160', 'var_161', 'var_162', 'var_163', 'var_164', 'var_165', 'var_166', 'var_167', 'var_168', 'var_169', 'var_170', 'var_171', 'var_172', 'var_173', 'var_174', 'var_175', 'var_176', 'var_177', 'var_178', 'var_179', 'var_180', 'var_181', 'var_182', 'var_183', 'var_184', 'var_185', 'var_186', 'var_187', 'var_188', 'var_189', 'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195', 'var_196', 'var_197', 'var_198', 'var_199']\n",
            "   INFO ->  start training model\n",
            "   INFO ->  (200000, 200)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on fold 1\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[100]\ttraining's auc: 0.788115\tvalid_1's auc: 0.758851\n",
            "[200]\ttraining's auc: 0.831817\tvalid_1's auc: 0.793005\n",
            "[300]\ttraining's auc: 0.857194\tvalid_1's auc: 0.812617\n",
            "[400]\ttraining's auc: 0.875021\tvalid_1's auc: 0.826367\n",
            "[500]\ttraining's auc: 0.887945\tvalid_1's auc: 0.835968\n",
            "[600]\ttraining's auc: 0.898185\tvalid_1's auc: 0.843639\n",
            "[700]\ttraining's auc: 0.906607\tvalid_1's auc: 0.850008\n",
            "[800]\ttraining's auc: 0.913944\tvalid_1's auc: 0.855596\n",
            "[900]\ttraining's auc: 0.920175\tvalid_1's auc: 0.860125\n",
            "[1000]\ttraining's auc: 0.925305\tvalid_1's auc: 0.863534\n",
            "[1100]\ttraining's auc: 0.929936\tvalid_1's auc: 0.866656\n",
            "[1200]\ttraining's auc: 0.933924\tvalid_1's auc: 0.869362\n",
            "[1300]\ttraining's auc: 0.937575\tvalid_1's auc: 0.871685\n",
            "[1400]\ttraining's auc: 0.940881\tvalid_1's auc: 0.873749\n",
            "[1500]\ttraining's auc: 0.943784\tvalid_1's auc: 0.875579\n",
            "[1600]\ttraining's auc: 0.946652\tvalid_1's auc: 0.877158\n",
            "[1700]\ttraining's auc: 0.949112\tvalid_1's auc: 0.878676\n",
            "[1800]\ttraining's auc: 0.951408\tvalid_1's auc: 0.880075\n",
            "[1900]\ttraining's auc: 0.953523\tvalid_1's auc: 0.881163\n",
            "[2000]\ttraining's auc: 0.955533\tvalid_1's auc: 0.882289\n",
            "[2100]\ttraining's auc: 0.957313\tvalid_1's auc: 0.883233\n",
            "[2200]\ttraining's auc: 0.95907\tvalid_1's auc: 0.884094\n",
            "[2300]\ttraining's auc: 0.960776\tvalid_1's auc: 0.88497\n",
            "[2400]\ttraining's auc: 0.962205\tvalid_1's auc: 0.885766\n",
            "[2500]\ttraining's auc: 0.963677\tvalid_1's auc: 0.886517\n",
            "[2600]\ttraining's auc: 0.96506\tvalid_1's auc: 0.887152\n",
            "[2700]\ttraining's auc: 0.966334\tvalid_1's auc: 0.887773\n",
            "[2800]\ttraining's auc: 0.967567\tvalid_1's auc: 0.88831\n",
            "[2900]\ttraining's auc: 0.968706\tvalid_1's auc: 0.888764\n",
            "[3000]\ttraining's auc: 0.969806\tvalid_1's auc: 0.889285\n",
            "[3100]\ttraining's auc: 0.970832\tvalid_1's auc: 0.889735\n",
            "[3200]\ttraining's auc: 0.971841\tvalid_1's auc: 0.890061\n",
            "[3300]\ttraining's auc: 0.972778\tvalid_1's auc: 0.89044\n",
            "[3400]\ttraining's auc: 0.973686\tvalid_1's auc: 0.89078\n",
            "[3500]\ttraining's auc: 0.974552\tvalid_1's auc: 0.891132\n",
            "[3600]\ttraining's auc: 0.975403\tvalid_1's auc: 0.891452\n",
            "[3700]\ttraining's auc: 0.976148\tvalid_1's auc: 0.891644\n",
            "[3800]\ttraining's auc: 0.976944\tvalid_1's auc: 0.891904\n",
            "[3900]\ttraining's auc: 0.977655\tvalid_1's auc: 0.892112\n",
            "[4000]\ttraining's auc: 0.978352\tvalid_1's auc: 0.892361\n",
            "[4100]\ttraining's auc: 0.979037\tvalid_1's auc: 0.892549\n",
            "[4200]\ttraining's auc: 0.979688\tvalid_1's auc: 0.892709\n",
            "[4300]\ttraining's auc: 0.980319\tvalid_1's auc: 0.892834\n",
            "[4400]\ttraining's auc: 0.980952\tvalid_1's auc: 0.892998\n",
            "[4500]\ttraining's auc: 0.981523\tvalid_1's auc: 0.893119\n",
            "[4600]\ttraining's auc: 0.982106\tvalid_1's auc: 0.89316\n",
            "[4700]\ttraining's auc: 0.982665\tvalid_1's auc: 0.893209\n",
            "[4800]\ttraining's auc: 0.983195\tvalid_1's auc: 0.893371\n",
            "[4900]\ttraining's auc: 0.983704\tvalid_1's auc: 0.893486\n",
            "[5000]\ttraining's auc: 0.984219\tvalid_1's auc: 0.893604\n",
            "[5100]\ttraining's auc: 0.984715\tvalid_1's auc: 0.893687\n",
            "[5200]\ttraining's auc: 0.985193\tvalid_1's auc: 0.893838\n",
            "[5300]\ttraining's auc: 0.985657\tvalid_1's auc: 0.893943\n",
            "[5400]\ttraining's auc: 0.986086\tvalid_1's auc: 0.893943\n",
            "[5500]\ttraining's auc: 0.986515\tvalid_1's auc: 0.893976\n",
            "[5600]\ttraining's auc: 0.986944\tvalid_1's auc: 0.894056\n",
            "[5700]\ttraining's auc: 0.987338\tvalid_1's auc: 0.894125\n",
            "[5800]\ttraining's auc: 0.987776\tvalid_1's auc: 0.894103\n",
            "Early stopping, best iteration is:\n",
            "[5685]\ttraining's auc: 0.987279\tvalid_1's auc: 0.894135\n",
            "AUC: 0.89413496509472\n",
            "Fold 1 finished in 0:09:53.586000\n",
            "Training on fold 2\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[100]\ttraining's auc: 0.790826\tvalid_1's auc: 0.757297\n",
            "[200]\ttraining's auc: 0.834228\tvalid_1's auc: 0.789976\n",
            "[300]\ttraining's auc: 0.85864\tvalid_1's auc: 0.808431\n",
            "[400]\ttraining's auc: 0.876037\tvalid_1's auc: 0.821986\n",
            "[500]\ttraining's auc: 0.888798\tvalid_1's auc: 0.83193\n",
            "[600]\ttraining's auc: 0.898817\tvalid_1's auc: 0.839817\n",
            "[700]\ttraining's auc: 0.906952\tvalid_1's auc: 0.846203\n",
            "[800]\ttraining's auc: 0.914155\tvalid_1's auc: 0.851174\n",
            "[900]\ttraining's auc: 0.920363\tvalid_1's auc: 0.855674\n",
            "[1000]\ttraining's auc: 0.925499\tvalid_1's auc: 0.859352\n",
            "[1100]\ttraining's auc: 0.930097\tvalid_1's auc: 0.862491\n",
            "[1200]\ttraining's auc: 0.93408\tvalid_1's auc: 0.865168\n",
            "[1300]\ttraining's auc: 0.937709\tvalid_1's auc: 0.867736\n",
            "[1400]\ttraining's auc: 0.940939\tvalid_1's auc: 0.869852\n",
            "[1500]\ttraining's auc: 0.943851\tvalid_1's auc: 0.871875\n",
            "[1600]\ttraining's auc: 0.94648\tvalid_1's auc: 0.873633\n",
            "[1700]\ttraining's auc: 0.948943\tvalid_1's auc: 0.875263\n",
            "[1800]\ttraining's auc: 0.951204\tvalid_1's auc: 0.87668\n",
            "[1900]\ttraining's auc: 0.953236\tvalid_1's auc: 0.87798\n",
            "[2000]\ttraining's auc: 0.955213\tvalid_1's auc: 0.879292\n",
            "[2100]\ttraining's auc: 0.957085\tvalid_1's auc: 0.880426\n",
            "[2200]\ttraining's auc: 0.95882\tvalid_1's auc: 0.881359\n",
            "[2300]\ttraining's auc: 0.960424\tvalid_1's auc: 0.882203\n",
            "[2400]\ttraining's auc: 0.961941\tvalid_1's auc: 0.883096\n",
            "[2500]\ttraining's auc: 0.963428\tvalid_1's auc: 0.883918\n",
            "[2600]\ttraining's auc: 0.964845\tvalid_1's auc: 0.884721\n",
            "[2700]\ttraining's auc: 0.96607\tvalid_1's auc: 0.885272\n",
            "[2800]\ttraining's auc: 0.967293\tvalid_1's auc: 0.885868\n",
            "[2900]\ttraining's auc: 0.968405\tvalid_1's auc: 0.886448\n",
            "[3000]\ttraining's auc: 0.969487\tvalid_1's auc: 0.887035\n",
            "[3100]\ttraining's auc: 0.970562\tvalid_1's auc: 0.887581\n",
            "[3200]\ttraining's auc: 0.971524\tvalid_1's auc: 0.888035\n",
            "[3300]\ttraining's auc: 0.972486\tvalid_1's auc: 0.888465\n",
            "[3400]\ttraining's auc: 0.973393\tvalid_1's auc: 0.888857\n",
            "[3500]\ttraining's auc: 0.974199\tvalid_1's auc: 0.889243\n",
            "[3600]\ttraining's auc: 0.975061\tvalid_1's auc: 0.889641\n",
            "[3700]\ttraining's auc: 0.975873\tvalid_1's auc: 0.889957\n",
            "[3800]\ttraining's auc: 0.976644\tvalid_1's auc: 0.890289\n",
            "[3900]\ttraining's auc: 0.977408\tvalid_1's auc: 0.890537\n",
            "[4000]\ttraining's auc: 0.978135\tvalid_1's auc: 0.890835\n",
            "[4100]\ttraining's auc: 0.97883\tvalid_1's auc: 0.891097\n",
            "[4200]\ttraining's auc: 0.979507\tvalid_1's auc: 0.891371\n",
            "[4300]\ttraining's auc: 0.980136\tvalid_1's auc: 0.891589\n",
            "[4400]\ttraining's auc: 0.980757\tvalid_1's auc: 0.891801\n",
            "[4500]\ttraining's auc: 0.981355\tvalid_1's auc: 0.891988\n",
            "[4600]\ttraining's auc: 0.981927\tvalid_1's auc: 0.892211\n",
            "[4700]\ttraining's auc: 0.982488\tvalid_1's auc: 0.892353\n",
            "[4800]\ttraining's auc: 0.983042\tvalid_1's auc: 0.892515\n",
            "[4900]\ttraining's auc: 0.983584\tvalid_1's auc: 0.892644\n",
            "[5000]\ttraining's auc: 0.984091\tvalid_1's auc: 0.8928\n",
            "[5100]\ttraining's auc: 0.984573\tvalid_1's auc: 0.892972\n",
            "[5200]\ttraining's auc: 0.985047\tvalid_1's auc: 0.893085\n",
            "[5300]\ttraining's auc: 0.985514\tvalid_1's auc: 0.893183\n",
            "[5400]\ttraining's auc: 0.985976\tvalid_1's auc: 0.893291\n",
            "[5500]\ttraining's auc: 0.986408\tvalid_1's auc: 0.893377\n",
            "[5600]\ttraining's auc: 0.986834\tvalid_1's auc: 0.89348\n",
            "[5700]\ttraining's auc: 0.987235\tvalid_1's auc: 0.893563\n",
            "[5800]\ttraining's auc: 0.987652\tvalid_1's auc: 0.893627\n",
            "[5900]\ttraining's auc: 0.988049\tvalid_1's auc: 0.893796\n",
            "[6000]\ttraining's auc: 0.988415\tvalid_1's auc: 0.893842\n",
            "[6100]\ttraining's auc: 0.988788\tvalid_1's auc: 0.893936\n",
            "[6200]\ttraining's auc: 0.98916\tvalid_1's auc: 0.893963\n",
            "[6300]\ttraining's auc: 0.989513\tvalid_1's auc: 0.894025\n",
            "[6400]\ttraining's auc: 0.989862\tvalid_1's auc: 0.894064\n",
            "[6500]\ttraining's auc: 0.990188\tvalid_1's auc: 0.894094\n",
            "[6600]\ttraining's auc: 0.990529\tvalid_1's auc: 0.894145\n",
            "[6700]\ttraining's auc: 0.990845\tvalid_1's auc: 0.894177\n",
            "[6800]\ttraining's auc: 0.991152\tvalid_1's auc: 0.89421\n",
            "[6900]\ttraining's auc: 0.991452\tvalid_1's auc: 0.894247\n",
            "[7000]\ttraining's auc: 0.991727\tvalid_1's auc: 0.894246\n",
            "[7100]\ttraining's auc: 0.992018\tvalid_1's auc: 0.894329\n",
            "[7200]\ttraining's auc: 0.992295\tvalid_1's auc: 0.894357\n",
            "[7300]\ttraining's auc: 0.992562\tvalid_1's auc: 0.894369\n",
            "[7400]\ttraining's auc: 0.992839\tvalid_1's auc: 0.894357\n",
            "[7500]\ttraining's auc: 0.993097\tvalid_1's auc: 0.894364\n",
            "Early stopping, best iteration is:\n",
            "[7350]\ttraining's auc: 0.992703\tvalid_1's auc: 0.894392\n",
            "AUC: 0.8943920216074868\n",
            "Fold 2 finished in 0:12:37.680584\n",
            "Training on fold 3\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[100]\ttraining's auc: 0.785644\tvalid_1's auc: 0.749586\n",
            "[200]\ttraining's auc: 0.832979\tvalid_1's auc: 0.790119\n",
            "[300]\ttraining's auc: 0.857593\tvalid_1's auc: 0.809981\n",
            "[400]\ttraining's auc: 0.875172\tvalid_1's auc: 0.823647\n",
            "[500]\ttraining's auc: 0.888235\tvalid_1's auc: 0.833918\n",
            "[600]\ttraining's auc: 0.898333\tvalid_1's auc: 0.841625\n",
            "[700]\ttraining's auc: 0.906844\tvalid_1's auc: 0.848079\n",
            "[800]\ttraining's auc: 0.913883\tvalid_1's auc: 0.853436\n",
            "[900]\ttraining's auc: 0.919942\tvalid_1's auc: 0.857819\n",
            "[1000]\ttraining's auc: 0.925089\tvalid_1's auc: 0.861602\n",
            "[1100]\ttraining's auc: 0.929691\tvalid_1's auc: 0.864731\n",
            "[1200]\ttraining's auc: 0.933768\tvalid_1's auc: 0.867487\n",
            "[1300]\ttraining's auc: 0.937301\tvalid_1's auc: 0.869982\n",
            "[1400]\ttraining's auc: 0.940605\tvalid_1's auc: 0.872152\n",
            "[1500]\ttraining's auc: 0.943606\tvalid_1's auc: 0.874016\n",
            "[1600]\ttraining's auc: 0.946184\tvalid_1's auc: 0.875607\n",
            "[1700]\ttraining's auc: 0.948726\tvalid_1's auc: 0.877189\n",
            "[1800]\ttraining's auc: 0.95099\tvalid_1's auc: 0.878491\n",
            "[1900]\ttraining's auc: 0.953205\tvalid_1's auc: 0.879801\n",
            "[2000]\ttraining's auc: 0.955139\tvalid_1's auc: 0.880921\n",
            "[2100]\ttraining's auc: 0.957039\tvalid_1's auc: 0.882018\n",
            "[2200]\ttraining's auc: 0.958748\tvalid_1's auc: 0.882969\n",
            "[2300]\ttraining's auc: 0.960407\tvalid_1's auc: 0.883782\n",
            "[2400]\ttraining's auc: 0.961881\tvalid_1's auc: 0.884632\n",
            "[2500]\ttraining's auc: 0.963264\tvalid_1's auc: 0.88533\n",
            "[2600]\ttraining's auc: 0.964725\tvalid_1's auc: 0.885973\n",
            "[2700]\ttraining's auc: 0.966045\tvalid_1's auc: 0.886557\n",
            "[2800]\ttraining's auc: 0.967241\tvalid_1's auc: 0.887223\n",
            "[2900]\ttraining's auc: 0.968412\tvalid_1's auc: 0.887762\n",
            "[3000]\ttraining's auc: 0.969448\tvalid_1's auc: 0.888224\n",
            "[3100]\ttraining's auc: 0.970534\tvalid_1's auc: 0.888636\n",
            "[3200]\ttraining's auc: 0.971531\tvalid_1's auc: 0.889\n",
            "[3300]\ttraining's auc: 0.972446\tvalid_1's auc: 0.889476\n",
            "[3400]\ttraining's auc: 0.973411\tvalid_1's auc: 0.889868\n",
            "[3500]\ttraining's auc: 0.974268\tvalid_1's auc: 0.890223\n",
            "[3600]\ttraining's auc: 0.975086\tvalid_1's auc: 0.890485\n",
            "[3700]\ttraining's auc: 0.97589\tvalid_1's auc: 0.890844\n",
            "[3800]\ttraining's auc: 0.976657\tvalid_1's auc: 0.891081\n",
            "[3900]\ttraining's auc: 0.977369\tvalid_1's auc: 0.891358\n",
            "[4000]\ttraining's auc: 0.97808\tvalid_1's auc: 0.891617\n",
            "[4100]\ttraining's auc: 0.978759\tvalid_1's auc: 0.891866\n",
            "[4200]\ttraining's auc: 0.97941\tvalid_1's auc: 0.892096\n",
            "[4300]\ttraining's auc: 0.98009\tvalid_1's auc: 0.89227\n",
            "[4400]\ttraining's auc: 0.9807\tvalid_1's auc: 0.89243\n",
            "[4500]\ttraining's auc: 0.981328\tvalid_1's auc: 0.892649\n",
            "[4600]\ttraining's auc: 0.981904\tvalid_1's auc: 0.892778\n",
            "[4700]\ttraining's auc: 0.98247\tvalid_1's auc: 0.892968\n",
            "[4800]\ttraining's auc: 0.983018\tvalid_1's auc: 0.893057\n",
            "[4900]\ttraining's auc: 0.983525\tvalid_1's auc: 0.893209\n",
            "[5000]\ttraining's auc: 0.984066\tvalid_1's auc: 0.893335\n",
            "[5100]\ttraining's auc: 0.984552\tvalid_1's auc: 0.893402\n",
            "[5200]\ttraining's auc: 0.98502\tvalid_1's auc: 0.893437\n",
            "[5300]\ttraining's auc: 0.985481\tvalid_1's auc: 0.893511\n",
            "[5400]\ttraining's auc: 0.985934\tvalid_1's auc: 0.893575\n",
            "[5500]\ttraining's auc: 0.986356\tvalid_1's auc: 0.893655\n",
            "[5600]\ttraining's auc: 0.986783\tvalid_1's auc: 0.893722\n",
            "[5700]\ttraining's auc: 0.987197\tvalid_1's auc: 0.893761\n",
            "[5800]\ttraining's auc: 0.987586\tvalid_1's auc: 0.893882\n",
            "[5900]\ttraining's auc: 0.987984\tvalid_1's auc: 0.893907\n",
            "[6000]\ttraining's auc: 0.988349\tvalid_1's auc: 0.89398\n",
            "[6100]\ttraining's auc: 0.988722\tvalid_1's auc: 0.894038\n",
            "[6200]\ttraining's auc: 0.989099\tvalid_1's auc: 0.894072\n",
            "[6300]\ttraining's auc: 0.989472\tvalid_1's auc: 0.894135\n",
            "[6400]\ttraining's auc: 0.989809\tvalid_1's auc: 0.894147\n",
            "[6500]\ttraining's auc: 0.99015\tvalid_1's auc: 0.894177\n",
            "[6600]\ttraining's auc: 0.990484\tvalid_1's auc: 0.89419\n",
            "[6700]\ttraining's auc: 0.990822\tvalid_1's auc: 0.894214\n",
            "[6800]\ttraining's auc: 0.991106\tvalid_1's auc: 0.894226\n",
            "[6900]\ttraining's auc: 0.991414\tvalid_1's auc: 0.894259\n",
            "[7000]\ttraining's auc: 0.991714\tvalid_1's auc: 0.894305\n",
            "[7100]\ttraining's auc: 0.992006\tvalid_1's auc: 0.894297\n",
            "Early stopping, best iteration is:\n",
            "[6977]\ttraining's auc: 0.991641\tvalid_1's auc: 0.894316\n",
            "AUC: 0.8943157679864263\n",
            "Fold 3 finished in 0:12:01.194589\n",
            "Training on fold 4\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[100]\ttraining's auc: 0.788566\tvalid_1's auc: 0.767042\n",
            "[200]\ttraining's auc: 0.83364\tvalid_1's auc: 0.80062\n",
            "[300]\ttraining's auc: 0.858496\tvalid_1's auc: 0.817976\n",
            "[400]\ttraining's auc: 0.877111\tvalid_1's auc: 0.830975\n",
            "[500]\ttraining's auc: 0.890014\tvalid_1's auc: 0.839968\n",
            "[600]\ttraining's auc: 0.899885\tvalid_1's auc: 0.846496\n",
            "[700]\ttraining's auc: 0.907803\tvalid_1's auc: 0.851468\n",
            "[800]\ttraining's auc: 0.91488\tvalid_1's auc: 0.855932\n",
            "[900]\ttraining's auc: 0.920619\tvalid_1's auc: 0.859542\n",
            "[1000]\ttraining's auc: 0.925663\tvalid_1's auc: 0.862758\n",
            "[1100]\ttraining's auc: 0.930307\tvalid_1's auc: 0.865538\n",
            "[1200]\ttraining's auc: 0.934228\tvalid_1's auc: 0.867937\n",
            "[1300]\ttraining's auc: 0.93778\tvalid_1's auc: 0.870282\n",
            "[1400]\ttraining's auc: 0.94099\tvalid_1's auc: 0.872308\n",
            "[1500]\ttraining's auc: 0.943946\tvalid_1's auc: 0.873884\n",
            "[1600]\ttraining's auc: 0.946547\tvalid_1's auc: 0.875447\n",
            "[1700]\ttraining's auc: 0.949012\tvalid_1's auc: 0.876911\n",
            "[1800]\ttraining's auc: 0.951244\tvalid_1's auc: 0.878193\n",
            "[1900]\ttraining's auc: 0.953385\tvalid_1's auc: 0.879383\n",
            "[2000]\ttraining's auc: 0.95534\tvalid_1's auc: 0.880507\n",
            "[2100]\ttraining's auc: 0.957146\tvalid_1's auc: 0.881543\n",
            "[2200]\ttraining's auc: 0.958817\tvalid_1's auc: 0.882502\n",
            "[2300]\ttraining's auc: 0.960413\tvalid_1's auc: 0.883496\n",
            "[2400]\ttraining's auc: 0.961913\tvalid_1's auc: 0.884319\n",
            "[2500]\ttraining's auc: 0.963325\tvalid_1's auc: 0.885013\n",
            "[2600]\ttraining's auc: 0.964706\tvalid_1's auc: 0.885693\n",
            "[2700]\ttraining's auc: 0.965947\tvalid_1's auc: 0.8863\n",
            "[2800]\ttraining's auc: 0.967208\tvalid_1's auc: 0.886852\n",
            "[2900]\ttraining's auc: 0.968336\tvalid_1's auc: 0.887324\n",
            "[3000]\ttraining's auc: 0.969463\tvalid_1's auc: 0.887833\n",
            "[3100]\ttraining's auc: 0.970541\tvalid_1's auc: 0.888257\n",
            "[3200]\ttraining's auc: 0.97152\tvalid_1's auc: 0.888664\n",
            "[3300]\ttraining's auc: 0.972456\tvalid_1's auc: 0.889018\n",
            "[3400]\ttraining's auc: 0.973372\tvalid_1's auc: 0.889416\n",
            "[3500]\ttraining's auc: 0.974263\tvalid_1's auc: 0.889799\n",
            "[3600]\ttraining's auc: 0.975075\tvalid_1's auc: 0.890071\n",
            "[3700]\ttraining's auc: 0.975882\tvalid_1's auc: 0.890384\n",
            "[3800]\ttraining's auc: 0.97664\tvalid_1's auc: 0.890653\n",
            "[3900]\ttraining's auc: 0.977361\tvalid_1's auc: 0.890941\n",
            "[4000]\ttraining's auc: 0.978057\tvalid_1's auc: 0.891163\n",
            "[4100]\ttraining's auc: 0.978789\tvalid_1's auc: 0.891344\n",
            "[4200]\ttraining's auc: 0.979478\tvalid_1's auc: 0.891572\n",
            "[4300]\ttraining's auc: 0.980125\tvalid_1's auc: 0.891785\n",
            "[4400]\ttraining's auc: 0.980744\tvalid_1's auc: 0.891954\n",
            "[4500]\ttraining's auc: 0.981333\tvalid_1's auc: 0.892098\n",
            "[4600]\ttraining's auc: 0.981931\tvalid_1's auc: 0.892242\n",
            "[4700]\ttraining's auc: 0.9825\tvalid_1's auc: 0.892381\n",
            "[4800]\ttraining's auc: 0.983042\tvalid_1's auc: 0.892449\n",
            "[4900]\ttraining's auc: 0.983553\tvalid_1's auc: 0.892578\n",
            "[5000]\ttraining's auc: 0.98407\tvalid_1's auc: 0.892648\n",
            "[5100]\ttraining's auc: 0.984582\tvalid_1's auc: 0.892814\n",
            "[5200]\ttraining's auc: 0.985053\tvalid_1's auc: 0.89289\n",
            "[5300]\ttraining's auc: 0.985523\tvalid_1's auc: 0.892922\n",
            "[5400]\ttraining's auc: 0.985955\tvalid_1's auc: 0.893017\n",
            "[5500]\ttraining's auc: 0.986377\tvalid_1's auc: 0.893117\n",
            "[5600]\ttraining's auc: 0.986813\tvalid_1's auc: 0.893199\n",
            "[5700]\ttraining's auc: 0.987241\tvalid_1's auc: 0.89325\n",
            "[5800]\ttraining's auc: 0.987661\tvalid_1's auc: 0.893314\n",
            "[5900]\ttraining's auc: 0.988049\tvalid_1's auc: 0.893341\n",
            "[6000]\ttraining's auc: 0.988425\tvalid_1's auc: 0.893401\n",
            "[6100]\ttraining's auc: 0.988802\tvalid_1's auc: 0.893437\n",
            "[6200]\ttraining's auc: 0.989184\tvalid_1's auc: 0.893471\n",
            "[6300]\ttraining's auc: 0.98956\tvalid_1's auc: 0.893506\n",
            "[6400]\ttraining's auc: 0.989885\tvalid_1's auc: 0.893592\n",
            "[6500]\ttraining's auc: 0.990222\tvalid_1's auc: 0.893644\n",
            "[6600]\ttraining's auc: 0.990554\tvalid_1's auc: 0.893721\n",
            "[6700]\ttraining's auc: 0.99086\tvalid_1's auc: 0.893699\n",
            "Early stopping, best iteration is:\n",
            "[6609]\ttraining's auc: 0.990584\tvalid_1's auc: 0.893723\n",
            "AUC: 0.8937234930555555\n",
            "Fold 4 finished in 0:11:33.081377\n",
            "Training on fold 5\n",
            "Training until validation scores don't improve for 150 rounds.\n",
            "[100]\ttraining's auc: 0.786494\tvalid_1's auc: 0.75402\n",
            "[200]\ttraining's auc: 0.831836\tvalid_1's auc: 0.792403\n",
            "[300]\ttraining's auc: 0.856347\tvalid_1's auc: 0.812035\n",
            "[400]\ttraining's auc: 0.875343\tvalid_1's auc: 0.826816\n",
            "[500]\ttraining's auc: 0.88831\tvalid_1's auc: 0.836667\n",
            "[600]\ttraining's auc: 0.898287\tvalid_1's auc: 0.844359\n",
            "[700]\ttraining's auc: 0.906976\tvalid_1's auc: 0.850635\n",
            "[800]\ttraining's auc: 0.914001\tvalid_1's auc: 0.855913\n",
            "[900]\ttraining's auc: 0.919901\tvalid_1's auc: 0.860224\n",
            "[1000]\ttraining's auc: 0.925129\tvalid_1's auc: 0.863916\n",
            "[1100]\ttraining's auc: 0.929765\tvalid_1's auc: 0.867148\n",
            "[1200]\ttraining's auc: 0.933805\tvalid_1's auc: 0.869824\n",
            "[1300]\ttraining's auc: 0.937489\tvalid_1's auc: 0.872163\n",
            "[1400]\ttraining's auc: 0.940889\tvalid_1's auc: 0.874344\n",
            "[1500]\ttraining's auc: 0.943884\tvalid_1's auc: 0.87632\n",
            "[1600]\ttraining's auc: 0.946494\tvalid_1's auc: 0.877843\n",
            "[1700]\ttraining's auc: 0.948963\tvalid_1's auc: 0.879511\n",
            "[1800]\ttraining's auc: 0.951172\tvalid_1's auc: 0.880757\n",
            "[1900]\ttraining's auc: 0.953449\tvalid_1's auc: 0.881978\n",
            "[2000]\ttraining's auc: 0.955388\tvalid_1's auc: 0.883118\n",
            "[2100]\ttraining's auc: 0.957194\tvalid_1's auc: 0.884033\n",
            "[2200]\ttraining's auc: 0.958801\tvalid_1's auc: 0.884819\n",
            "[2300]\ttraining's auc: 0.960466\tvalid_1's auc: 0.885673\n",
            "[2400]\ttraining's auc: 0.961996\tvalid_1's auc: 0.88645\n",
            "[2500]\ttraining's auc: 0.963456\tvalid_1's auc: 0.887171\n",
            "[2600]\ttraining's auc: 0.964783\tvalid_1's auc: 0.88778\n",
            "[2700]\ttraining's auc: 0.966025\tvalid_1's auc: 0.888306\n",
            "[2800]\ttraining's auc: 0.967244\tvalid_1's auc: 0.888933\n",
            "[2900]\ttraining's auc: 0.968336\tvalid_1's auc: 0.889444\n",
            "[3000]\ttraining's auc: 0.969422\tvalid_1's auc: 0.889849\n",
            "[3100]\ttraining's auc: 0.970461\tvalid_1's auc: 0.890227\n",
            "[3200]\ttraining's auc: 0.971459\tvalid_1's auc: 0.89063\n",
            "[3300]\ttraining's auc: 0.972398\tvalid_1's auc: 0.891002\n",
            "[3400]\ttraining's auc: 0.973292\tvalid_1's auc: 0.891395\n",
            "[3500]\ttraining's auc: 0.974145\tvalid_1's auc: 0.891705\n",
            "[3600]\ttraining's auc: 0.975015\tvalid_1's auc: 0.891992\n",
            "[3700]\ttraining's auc: 0.975815\tvalid_1's auc: 0.892287\n",
            "[3800]\ttraining's auc: 0.976558\tvalid_1's auc: 0.892639\n",
            "[3900]\ttraining's auc: 0.977306\tvalid_1's auc: 0.892895\n",
            "[4000]\ttraining's auc: 0.977998\tvalid_1's auc: 0.893097\n",
            "[4100]\ttraining's auc: 0.978674\tvalid_1's auc: 0.893299\n",
            "[4200]\ttraining's auc: 0.979365\tvalid_1's auc: 0.893447\n",
            "[4300]\ttraining's auc: 0.98003\tvalid_1's auc: 0.893635\n",
            "[4400]\ttraining's auc: 0.980645\tvalid_1's auc: 0.893846\n",
            "[4500]\ttraining's auc: 0.981243\tvalid_1's auc: 0.894059\n",
            "[4600]\ttraining's auc: 0.981821\tvalid_1's auc: 0.894209\n",
            "[4700]\ttraining's auc: 0.982421\tvalid_1's auc: 0.894382\n",
            "[4800]\ttraining's auc: 0.982989\tvalid_1's auc: 0.894522\n",
            "[4900]\ttraining's auc: 0.983499\tvalid_1's auc: 0.894701\n",
            "[5000]\ttraining's auc: 0.984019\tvalid_1's auc: 0.894783\n",
            "[5100]\ttraining's auc: 0.984538\tvalid_1's auc: 0.894908\n",
            "[5200]\ttraining's auc: 0.985012\tvalid_1's auc: 0.894983\n",
            "[5300]\ttraining's auc: 0.985482\tvalid_1's auc: 0.895042\n",
            "[5400]\ttraining's auc: 0.985933\tvalid_1's auc: 0.895137\n",
            "[5500]\ttraining's auc: 0.986396\tvalid_1's auc: 0.895225\n",
            "[5600]\ttraining's auc: 0.986804\tvalid_1's auc: 0.89528\n",
            "[5700]\ttraining's auc: 0.98723\tvalid_1's auc: 0.895344\n",
            "[5800]\ttraining's auc: 0.987663\tvalid_1's auc: 0.89543\n",
            "[5900]\ttraining's auc: 0.988051\tvalid_1's auc: 0.895449\n",
            "[6000]\ttraining's auc: 0.98844\tvalid_1's auc: 0.895522\n",
            "[6100]\ttraining's auc: 0.988824\tvalid_1's auc: 0.895588\n",
            "[6200]\ttraining's auc: 0.989196\tvalid_1's auc: 0.895612\n",
            "[6300]\ttraining's auc: 0.989565\tvalid_1's auc: 0.895665\n",
            "[6400]\ttraining's auc: 0.989919\tvalid_1's auc: 0.89569\n",
            "[6500]\ttraining's auc: 0.990248\tvalid_1's auc: 0.895685\n",
            "[6600]\ttraining's auc: 0.990592\tvalid_1's auc: 0.895702\n",
            "[6700]\ttraining's auc: 0.990907\tvalid_1's auc: 0.895702\n",
            "Early stopping, best iteration is:\n",
            "[6573]\ttraining's auc: 0.9905\tvalid_1's auc: 0.895732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "   INFO ->  (200000, 200)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.8957324044673495\n",
            "Fold 5 finished in 0:11:25.639494\n",
            "Training on fold 1\n"
          ]
        }
      ],
      "source": [
        "sub = autox.get_submit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6KaTZzcmkZ3"
      },
      "outputs": [],
      "source": [
        "sub.to_csv(\"./autox_Santander.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K33r9mdwn6h3"
      },
      "source": [
        "更多教程请参考: [autox](https://github.com/4paradigm/autox?spm=5176.21852664.0.0.5594640eeR1PoH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwR3FOb0mo6K"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "autox_tutorial_santander.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}